{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words: Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['fun' 'is' 'love' 'programming']\n",
      "BoW Matrix:\n",
      " [[0 0 1 1]\n",
      " [1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample data\n",
    "documents = [\"I love programming.\", \"Programming is fun.\"]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the result to an array and print\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())  # Get the vocabulary\n",
    "print(\"BoW Matrix:\\n\", X.toarray())  # Display the document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "* The CountVectorizer converts the text data into a matrix where each column represents a word from the vocabulary.\n",
    "* The rows represent the individual documents, and the values are the counts of each word in those documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF: Implementation\n",
    "Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "TF-IDF highlights terms that uniquely represent a document by penalizing terms that are common across many documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['fun' 'is' 'love' 'programming']\n",
      "TF-IDF Matrix:\n",
      " [[0.         0.         0.81480247 0.57973867]\n",
      " [0.6316672  0.6316672  0.         0.44943642]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample data\n",
    "documents = [\"I love programming.\", \"Programming is fun.\"]\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the result to an array and print\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())  # Get the vocabulary\n",
    "print(\"TF-IDF Matrix:\\n\", X.toarray())  # Display the TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "* The TfidfVectorizer computes the TF-IDF score for each word. The higher the score, the more relevant the word is in that document relative to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When should you use Bag of Words instead of TF-IDF?\n",
    "\n",
    "When you want to focus on word frequency regardless of document context.  Bag of Words focuses purely on word counts, while TF-IDF incorporates the importance of words relative to a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Implement Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['deep' 'fun' 'is' 'learning' 'machine' 'of' 'subset']\n",
      "[[0 1 1 1 1 0 0]\n",
      " [1 0 1 2 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample data\n",
    "documents = [\"Machine learning is fun.\", \"Deep learning is a subset of machine learning.\"]\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Display the vocabulary and the BoW matrix\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())  # Get the vocabulary\n",
    "# BoW Matrix:\n",
    "print(X.toarray())  # Display the document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint : \n",
    "* Think about how CountVectorizer works. It tokenizes the text into words and counts the occurrence of each word in the documents.\n",
    "* The get_feature_names_out() function will give you the list of words in your vocabulary.\n",
    "* The toarray() method will show the term frequencies (counts) of each word in each document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Implement TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['deep' 'fun' 'is' 'learning' 'machine' 'of' 'subset']\n",
      "[[0.         0.63009934 0.44832087 0.44832087 0.44832087 0.\n",
      "  0.        ]\n",
      " [0.40697968 0.         0.2895694  0.57913879 0.2895694  0.40697968\n",
      "  0.40697968]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample data\n",
    "documents = [\"Machine learning is fun.\", \"Deep learning is a subset of machine learning.\"]\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Display the vocabulary and the TF-IDF matrix\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())  # Get the vocabulary\n",
    "# TF-IDF Matrix:\n",
    "print(X.toarray())  # Display the TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: \n",
    "\n",
    "* The TfidfVectorizer works similarly to CountVectorizer, but it also adjusts the term frequencies by the importance of each word across documents.\n",
    "* Check out the difference between the TF-IDF values and the word counts from BoW. High values show the importance of words that appear less frequently across documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Comparing Bag of Words and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 1 0 0 0 1]\n",
      " [1 0 0 0 0 1 1 1 1]\n",
      " [1 1 0 1 1 0 1 0 1]]\n",
      "[[0.39148397 0.         0.66283998 0.         0.50410689 0.\n",
      "  0.         0.         0.39148397]\n",
      " [0.32630952 0.         0.         0.         0.         0.55249005\n",
      "  0.42018292 0.55249005 0.32630952]\n",
      " [0.30083189 0.50935267 0.         0.50935267 0.38737583 0.\n",
      "  0.38737583 0.         0.30083189]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Sample data\n",
    "documents = [\"Data science is exciting!\", \"Data science requires programming knowledge.\", \"Programming is essential for data science.\"]\n",
    "\n",
    "# Initialize the CountVectorizer and TfidfVectorizer\n",
    "vectorizer_bow = CountVectorizer()\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents using both vectorizers\n",
    "X_bow = vectorizer_bow.fit_transform(documents)\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(documents)\n",
    "\n",
    "# Display the results\n",
    "# BoW Matrix:\n",
    "print(X_bow.toarray())\n",
    "# TF-IDF Matrix:\n",
    "print(X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For BoW, you should observe the frequency of words in each document. Words that appear in multiple documents will have higher values.\n",
    "* For TF-IDF, remember that frequent words like \"data\" and \"science\" may have lower values due to their prevalence across documents.\n",
    "* Compare the two matrices to see how TF-IDF adjusts the term frequencies to reflect the significance of words in each document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
