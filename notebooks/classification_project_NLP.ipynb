{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dianaterraza/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np  # for numerical operations\n",
    "import pandas as pd  # for data manipulation\n",
    "import random  # for shuffling the data\n",
    "import nltk\n",
    "import re  # for handling regular expressions\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer  # for lemmatizing words\n",
    "from nltk.corpus import stopwords  # for stop word removal\n",
    "from nltk.tokenize import word_tokenize  # for tokenizing sentences into words\n",
    "nltk.download('punkt_tab')  # Downloads the 'punkt' tokenizer table used for tokenization of text into sentences or words\n",
    "\n",
    "# Downloading necessary NLTK resources\n",
    "nltk.download('stopwords')  # List of common stop words in English\n",
    "nltk.download('punkt')  # Pre-trained tokenizer models\n",
    "nltk.download('wordnet')  # WordNet lemmatizer dataset\n",
    "\n",
    "# Libraries for text feature extraction and model training\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Convert text into numerical features (TF-IDF)\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic regression for classification\n",
    "from sklearn.svm import LinearSVC  # Support Vector Machines for classification\n",
    "\n",
    "# Libraries for model evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix  # For model evaluation metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score  # For cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load & Prepare Dataset\n",
    "\n",
    "The Sentence Polarity dataset contains 5,331 positive and 5,331 negative sentences. We'll load this dataset and prepare it for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/dianaterraza/.cache/kagglehub/datasets/nltkdata/sentence-polarity/versions/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download a single file\n",
    "kagglehub.dataset_download('bricevergnou/spotify-recommendation', path='data.csv')\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  the rock is destined to be the 21st century's ...\n",
      "1  the gorgeously elaborate continuation of \" the...\n",
      "2                     effective but too-tepid biopic\n",
      "3  if you sometimes like to go to the movies to h...\n",
      "4  emerges as something rare , an issue movie tha...\n"
     ]
    }
   ],
   "source": [
    "# Read the positive and negative sentiment files\n",
    "df_sent_pos = pd.read_csv('/Users/dianaterraza/Desktop/NLP/Data/sentence_polarity 2/rt-polarity.pos', sep='\\t', header=None)  # Positive sentiment sentences\n",
    "df_sent_neg = pd.read_csv('/Users/dianaterraza/Desktop/NLP/Data/sentence_polarity 2/rt-polarity.neg', sep='\\t', header=None)  # Negative sentiment sentences\n",
    "\n",
    "# Display the first few rows of the positive dataset to understand its structure\n",
    "print(df_sent_pos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column to 'sentence'\n",
    "df_sent_pos.rename(columns={0: \"sentence\"}, inplace=True)\n",
    "df_sent_neg.rename(columns={0: \"sentence\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inplace=True ensures the changes are applied directly to the dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Converts text to lowercase.\n",
    "2. Removes punctuation using regular expressions.\n",
    "3. Removes extra whitespace.\n",
    "4. Tokenizes sentences into words.\n",
    "5. Removes stop words.\n",
    "6. Lemmatizes words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_text(sentences):\n",
    "    # Convert all tokens to lowercase\n",
    "    sentences = [sentence.lower() for sentence in sentences]\n",
    "\n",
    "    # Remove punctuation using regex\n",
    "    sentences = [re.sub(r\"[^\\w\\s]\", \"\", sentence) for sentence in sentences]\n",
    "\n",
    "    # Remove extra whitespaces between words\n",
    "    sentences = [\" \".join(sentence.split()) for sentence in sentences]\n",
    "\n",
    "    # Tokenize sentences into words\n",
    "    sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))  # Load English stop words\n",
    "    filtered_sentences = []\n",
    "    for sentence in sentences:\n",
    "        filtered_sentence = [word for word in sentence if word not in stop_words]\n",
    "        filtered_sentences.append(filtered_sentence)\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentences = []\n",
    "    for sentence in filtered_sentences:\n",
    "        lemmatized_sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "        lemmatized_sentences.append(lemmatized_sentence)\n",
    "\n",
    "    return [' '.join(sentence) for sentence in lemmatized_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each preprocessing step cleans the text data and prepares it for model training.\n",
    "* Stop words like \"the\", \"is\", and \"and\" are removed to focus on meaningful words.\n",
    "* Lemmatization reduces words to their base form (e.g., \"running\" â†’ \"run\").\n",
    "* Note what we pass after the return keyword! [' '.join(sentence) for sentence in lemmatized_sentences] does an important step for us: it collects separate tokens back to a string. Here is a concrete example: we move from ['simplistic', 'silly', 'tedious'] to `\n",
    "simplistic silly tedious. In other words, we move from a list of tokens to a single sentence in a form of a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Apply Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplistic silly tedious\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the sentences\n",
    "pos_preprocessed_sentences = preprocess_text(df_sent_pos['sentence'])\n",
    "neg_preprocessed_sentences = preprocess_text(df_sent_neg['sentence'])\n",
    "\n",
    "# Print the first preprocessed negative sentence\n",
    "print(neg_preprocessed_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Combine Datasets\n",
    "\n",
    "We merge the positive and negative sentences into a single list called sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine preprocessed positive and negative sentences\n",
    "sentences = pos_preprocessed_sentences + neg_preprocessed_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Create Labels\n",
    "\n",
    "Labels (also called targets) distinguish positive and negative sentences. Positive sentences are labeled as 1, and negative ones as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for all labels\n",
    "polarities = []\n",
    "polarities.extend([0] * len(df_sent_neg))  # Label negative sentences as 0\n",
    "polarities.extend([1] * len(df_sent_pos))  # Label positive sentences as 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the polarities list matches the sentences list, maintaining the correct label for each sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sentences and labels into a single list\n",
    "combined = list(zip(sentences, polarities))\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(combined)\n",
    "\n",
    "# Split the shuffled list back into sentences and labels\n",
    "sentences[:], polarities[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Split Dataset\n",
    "\n",
    "Weâ€™ll split the data into training and test sets, using 80% for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 8529\n",
      "Size of test set: 2133\n"
     ]
    }
   ],
   "source": [
    "# Define train-test split ratio\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "# Calculate the size of the training set\n",
    "train_set_size = int(train_test_ratio * len(sentences))\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test = sentences[:train_set_size], sentences[train_set_size:]\n",
    "y_train, y_test = polarities[:train_set_size], polarities[train_set_size:]\n",
    "\n",
    "# Print sizes of training and test sets\n",
    "print(\"Size of training set:\", len(X_train))\n",
    "print(\"Size of test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Texts, Training Models & Evaluating Their Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transforming Text into Features\n",
    "\n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency \n",
    "\n",
    "The TF-IDF Vectorizer is a widely used tool for this purpose. It transforms sentences into a sparse matrix where each row corresponds to a document (sentence) and each column represents a term (word or token)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, weâ€™ll use the TfidfVectorizer out of the box with its default configuration. By default, this includes:\n",
    "* Only unigrams (individual terms/tokens) as features.\n",
    "* A maximum document frequency of 1.0 (no terms are excluded based on frequency).\n",
    "* Normalization applied to the resulting feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Samples: 8529, #Features: 16486\n"
     ]
    }
   ],
   "source": [
    "# Import TF-IDF Vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the vectorizer with default parameters\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the training data into a TF-IDF matrix\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Check the number of samples and features\n",
    "num_samples, num_features = X_train_tfidf.shape\n",
    "print(\"#Samples: {}, #Features: {}\".format(num_samples, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a simple yet effective algorithm for binary classification tasks, such as predicting sentiment polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "logistic_regression_classifier = LogisticRegression().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluating the Classifier\n",
    "\n",
    "After training the model, we need to assess its performance on unseen test data. Evaluation involves transforming the test data into the same TF-IDF format as the training data, making predictions, and calculating key metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Transform Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general rule here is that .fit_transform() is always used for the training data and .transform() for any other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data into TF-IDF format\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Predict Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict polarities for the test data\n",
    "y_pred = logistic_regression_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Generate Evaluation Report\n",
    "\n",
    "We use the classification_report() function to generate precision, recall, and F1-score metrics for each class, as well as the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      1061\n",
      "           1       0.75      0.75      0.75      1072\n",
      "\n",
      "    accuracy                           0.75      2133\n",
      "   macro avg       0.75      0.75      0.75      2133\n",
      "weighted avg       0.75      0.75      0.75      2133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Generate and display the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interpreting the Results\n",
    "Letâ€™s break down the key metrics:\n",
    "* Precision: How many of the modelâ€™s positive predictions were correct? For example, the precision for class 0 (negative sentiment) is 75%, meaning 75% of the sentences predicted as negative were actually negative.\n",
    "\n",
    "* Recall: How many of the actual positive cases were correctly identified? For class 1 (positive sentiment), the recall is 75%, meaning the model correctly identified 75% of all positive sentences.\n",
    "\n",
    "* F1-score: This is the harmonic mean of precision and recall, providing a balanced measure. In this example, both classes have an F1-score of 0.75.\n",
    "\n",
    "### Is 75% a Good F1-Score?\n",
    "A random classifier for a binary task would achieve an F1-score of ~50%.\n",
    "Our modelâ€™s F1-score of 75% shows that it performs significantly better than random guessing. However, itâ€™s not perfect, indicating room for improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
